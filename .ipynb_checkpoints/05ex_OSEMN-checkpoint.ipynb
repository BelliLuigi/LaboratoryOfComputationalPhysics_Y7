{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OSEMN Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Create a random list of number and then save it to a text file named \"simple_data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "import numpy.random as npr\n",
    "\n",
    "np.set_printoptions(precision=2) # 4 readability\n",
    "\n",
    "simple_data = npr.random((10,10)) #10x10 matrix\n",
    "#print(simple_data)\n",
    "simple_data_str = str(simple_data) #make it string\n",
    "simple_data_str = simple_data_str.replace('[', '') #replacing\n",
    "simple_data_str = simple_data_str.replace(']', '')\n",
    "#print(simple_data_str.find('\\n'))\n",
    "\n",
    "f = open('simple_data.txt', 'w') \n",
    "f.write(str(simple_data_str))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Create a random matrix of 5x5 and then save it to a text file named \"data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "randmat = npr.random((5,5)) *3.2\n",
    "strandmat = str(randmat)\n",
    "strandmat = strandmat.replace('[', '')\n",
    "strandmat = strandmat.replace(']', '')\n",
    "f = open('data.txt', 'w')\n",
    "f.write(strandmat)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Load the saved txt file of point 2 and convert it to a csv file (by hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.45,1.99,0.32,1.37,0.53\n",
      " 2.77,0.86,1.49,3.2, 1.01\n",
      " 1.85,0.51,1.95,0.55,1.88\n",
      " 0.11,2.23,2.6, 1.03,1.89\n",
      " 1.7, 2.44,0.15,1.85,0.3,\n"
     ]
    }
   ],
   "source": [
    "file = open('data.txt','r')\n",
    "sfile = file.read()\n",
    "commafile = re.sub(r'(?<=[0-9]) ', ',', sfile) #look behind thing. THe thing inside the parentesis is part of the pattern but it is not substituted.\n",
    "print(commafile)\n",
    "file.close()\n",
    "commas = open('data.csv', 'w')\n",
    "commas.write(commafile)\n",
    "commas.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. load the binary file named *credit_card.dat* and convert the data into the real credit-card number.\n",
    "Each line correspond to a credit card number.\n",
    "Each character is composed by 6 bit (even the space) and the last 4 bit are just a padding\n",
    "\n",
    "**hint**: use the `chr()` function to convert a number to a char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with  open('credit_card.dat','rb') as file:\n",
    "    file_content=file.read()\n",
    "    file_content = str(file_content).replace('b','').replace(\"'\", \"\").split(r\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "listofcc = []\n",
    "for cc in file_content: # chr(int(str(char),2))\n",
    "    ccn = ''\n",
    "    for char in range(0,len(cc)-4,6):\n",
    "        ccn += chr(int(str(cc[char:char+6]),2))\n",
    "    listofcc.append(ccn)\n",
    "listofcc = listofcc[:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Load the file \"user_data.json\", filter the data by the \"CreditCardType\" field equals to \"American Express\". Than save the data a to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = json.load(open('user_data.json'))\n",
    "American_Express_users = [user for user in user_data if user['CreditCardType'] == 'American Express']\n",
    "\n",
    "list = [','.join(map(str, user.values())) + '\\n' for user in American_Express_users]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = json.load(open('user_data.json'))\n",
    "amex_usr = [i for i in data if i['CreditCardType']=='American Express']\n",
    "\n",
    "with open('American_Express_users.csv', 'w') as f:\n",
    "    for user in amex_usr:\n",
    "        f.write(','.join(map(str, user.values())) + '\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Load the file from this url: [https://www.dropbox.com/s/7u3lm737ogbqsg8/mushrooms_categorized.csv?dl=1](https://www.dropbox.com/s/7u3lm737ogbqsg8/mushrooms_categorized.csv?dl=1) with Pandas. \n",
    "+ Explore the data (see the info of the data)\n",
    "+ Draw the istogram of the 'class' field. Decribe wath yuou see\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Load the remote file [https://www.dropbox.com/s/vkl89yce7xjdq4n/regression_generated.csv?dl=1](https://www.dropbox.com/s/vkl89yce7xjdq4n/regression_generated.csv?dl=1) with Pandas and plot a scatter plot all possible combination of the following fields:\n",
    "    \n",
    "  + features_1\n",
    "  + features_2\n",
    "  + features_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. Load the same file of point 6, and convert the file to json with Pandas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
